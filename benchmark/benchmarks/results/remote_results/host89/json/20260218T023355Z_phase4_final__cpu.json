{
  "meta": {
    "timestamp_utc": "2026-02-18T02:33:57.325322+00:00",
    "host": "90c892d22de7",
    "os": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35",
    "python": "3.11.11",
    "device": "cpu",
    "batch": 64,
    "hidden": 2048,
    "iters": 40,
    "warmup": 10,
    "tag": "cpu",
    "adapters": [
      "torch_eager",
      "torch_compile",
      "pyc",
      "tvm",
      "xla",
      "tensorrt",
      "glow"
    ],
    "run_id": "20260218T023355Z_phase4_final",
    "git_head": "unknown",
    "git_dirty": 0
  },
  "gpu": {
    "available": true,
    "gpus": [
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      },
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      }
    ]
  },
  "adapters": {
    "torch_eager": {
      "status": "ok",
      "backend": "torch_eager",
      "mode": "native",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 36.9971,
        "p50": 15.4305,
        "p95": 75.9299,
        "min": 14.1421,
        "max": 83.1174
      },
      "throughput_tokens_per_sec": 3542766.92,
      "peak_memory_bytes": 0,
      "samples_ms": [
        74.2416,
        15.207,
        14.2293,
        72.5699,
        14.4432,
        15.0643,
        76.4769,
        15.2572,
        73.2536,
        14.2321,
        15.4392,
        71.8496,
        15.4305,
        14.1421,
        74.3565,
        14.556,
        14.1791,
        75.9299,
        14.4363,
        14.959,
        68.8835,
        14.3091,
        14.8224,
        75.2606,
        15.9354,
        72.1309,
        17.7051,
        15.5378,
        75.0194,
        15.1961,
        14.5832,
        69.2268,
        14.9607,
        15.1987,
        83.1174,
        15.0304,
        70.2721,
        14.3308,
        14.3476,
        73.7618
      ],
      "adapter": "torch_eager",
      "display_name": "PyTorch Eager"
    },
    "torch_compile": {
      "status": "ok",
      "backend": "torch_compile",
      "mode": "native",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 26.7237,
        "p50": 10.0514,
        "p95": 72.1404,
        "min": 9.8348,
        "max": 73.3309
      },
      "throughput_tokens_per_sec": 4904708.07,
      "peak_memory_bytes": 0,
      "samples_ms": [
        68.2249,
        9.9563,
        10.0168,
        9.8348,
        72.1404,
        9.9153,
        12.697,
        70.2607,
        10.1567,
        9.8918,
        9.9065,
        70.0966,
        13.0391,
        10.1845,
        10.1969,
        67.1376,
        10.2147,
        9.8455,
        9.9995,
        69.4201,
        13.6314,
        9.9059,
        9.9639,
        70.058,
        10.0514,
        9.9441,
        9.9238,
        73.3309,
        9.993,
        10.0051,
        10.0033,
        68.4708,
        10.0517,
        9.8894,
        9.913,
        72.2766,
        10.001,
        9.9755,
        9.9827,
        68.441
      ],
      "adapter": "torch_compile",
      "display_name": "PyTorch Compile"
    },
    "pyc": {
      "status": "ok",
      "backend": "pyc_compiler_next",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 24.0459,
        "p50": 24.022,
        "p95": 24.18,
        "min": 23.863,
        "max": 24.335
      },
      "throughput_tokens_per_sec": 5450908.47,
      "peak_memory_bytes": 17825792,
      "profile": {
        "dispatch_ms_mean": 24.0373,
        "graph_exec_ms_mean": 24.0373,
        "controller_ms_mean": 0.0005,
        "kernel_select_ms_mean": 0.0009
      },
      "reliability": {
        "compile_cache_hit": 0,
        "compile_budget_exceeded": 0,
        "guard_miss_count": 0,
        "fallback_count": 0,
        "graph_break_count": 0,
        "compilability_score": 1.0,
        "autotune_loaded": 0,
        "autotune_saved": 0
      },
      "mode": "native",
      "note": "PyC benchmark uses compiler-next API path; CUDA currently executes deterministic fallback until native kernels land.",
      "adapter": "pyc",
      "display_name": "PyC CUDA"
    },
    "tvm": {
      "status": "unavailable",
      "reason": "TVM not installed; install TVM or change TVM_BENCH_CMD",
      "adapter": "tvm",
      "display_name": "TVM",
      "mode": "unknown"
    },
    "xla": {
      "status": "ok",
      "backend": "xla_proxy_torch",
      "mode": "proxy",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 30.2406,
        "p50": 12.8271,
        "p95": 72.3854,
        "min": 11.8779,
        "max": 73.3976
      },
      "throughput_tokens_per_sec": 4334310.06,
      "peak_memory_bytes": 0,
      "note": "torch_xla path unavailable; executed deterministic torch proxy workload.",
      "adapter": "xla",
      "display_name": "XLA"
    },
    "tensorrt": {
      "status": "ok",
      "backend": "tensorrt_proxy_torch_compile",
      "mode": "proxy",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 24.4121,
        "p50": 9.3322,
        "p95": 68.6434,
        "min": 8.7147,
        "max": 73.2557
      },
      "throughput_tokens_per_sec": 5369130.72,
      "peak_memory_bytes": 0,
      "note": "TensorRT is CUDA-only; executed deterministic torch.compile proxy on CPU.",
      "adapter": "tensorrt",
      "display_name": "TensorRT"
    },
    "glow": {
      "status": "ok",
      "backend": "glow_proxy",
      "mode": "proxy",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 34.8523,
        "p50": 15.7008,
        "p95": 75.1887,
        "min": 12.4644,
        "max": 76.977
      },
      "throughput_tokens_per_sec": 3760782.37,
      "peak_memory_bytes": 0,
      "note": "Glow runtime is not linked in this environment; this is a deterministic proxy workload.",
      "adapter": "glow",
      "display_name": "Glow"
    }
  }
}
