{
  "meta": {
    "timestamp_utc": "2026-02-18T00:46:49.983806+00:00",
    "host": "90c892d22de7",
    "os": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35",
    "python": "3.11.11",
    "device": "cuda",
    "batch": 64,
    "hidden": 2048,
    "iters": 80,
    "warmup": 20,
    "tag": "host89_gpu_compare",
    "adapters": [
      "torch_eager",
      "torch_compile",
      "pyc",
      "tvm",
      "xla",
      "tensorrt",
      "glow"
    ]
  },
  "gpu": {
    "available": true,
    "gpus": [
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      },
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      }
    ]
  },
  "adapters": {
    "torch_eager": {
      "status": "ok",
      "backend": "torch_eager",
      "device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 80,
      "warmup": 20,
      "latency_ms": {
        "mean": 0.1174,
        "p50": 0.1149,
        "p95": 0.1362,
        "min": 0.1121,
        "max": 0.1561
      },
      "throughput_tokens_per_sec": 1116454921.5,
      "peak_memory_bytes": 78541312,
      "samples_ms": [
        0.1157,
        0.1389,
        0.1167,
        0.117,
        0.1151,
        0.1173,
        0.1161,
        0.1156,
        0.1362,
        0.1561,
        0.1167,
        0.116,
        0.116,
        0.1182,
        0.1216,
        0.1161,
        0.1255,
        0.1184,
        0.1146,
        0.1151,
        0.1144,
        0.1143,
        0.1146,
        0.1144,
        0.114,
        0.1438,
        0.1165,
        0.1154,
        0.1195,
        0.1149,
        0.1149,
        0.1147,
        0.1221,
        0.1175,
        0.1154,
        0.1153,
        0.1146,
        0.1143,
        0.1131,
        0.1173,
        0.1127,
        0.1264,
        0.1147,
        0.1151,
        0.114,
        0.1134,
        0.1136,
        0.1132,
        0.113,
        0.1288,
        0.1129,
        0.1143,
        0.1138,
        0.1132,
        0.1132,
        0.113,
        0.1134,
        0.128,
        0.1154,
        0.1121,
        0.113,
        0.1133,
        0.1137,
        0.1134,
        0.1142,
        0.1387,
        0.1191,
        0.1139,
        0.1135,
        0.115,
        0.1188,
        0.1134,
        0.1136,
        0.1141,
        0.1183,
        0.114,
        0.1132,
        0.1138,
        0.1134,
        0.1135
      ],
      "adapter": "torch_eager",
      "display_name": "PyTorch Eager"
    },
    "torch_compile": {
      "status": "ok",
      "backend": "torch_compile",
      "device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 80,
      "warmup": 20,
      "latency_ms": {
        "mean": 0.1569,
        "p50": 0.1557,
        "p95": 0.1648,
        "min": 0.1527,
        "max": 0.1936
      },
      "throughput_tokens_per_sec": 835404648.44,
      "peak_memory_bytes": 380264448,
      "samples_ms": [
        0.1577,
        0.1561,
        0.1568,
        0.1568,
        0.1661,
        0.1567,
        0.1557,
        0.1549,
        0.1559,
        0.1564,
        0.1649,
        0.1567,
        0.1547,
        0.1575,
        0.1552,
        0.1573,
        0.1936,
        0.1581,
        0.1554,
        0.1562,
        0.155,
        0.1556,
        0.1648,
        0.1569,
        0.1536,
        0.1553,
        0.1552,
        0.1561,
        0.1631,
        0.1557,
        0.1544,
        0.1557,
        0.1561,
        0.1552,
        0.1624,
        0.1557,
        0.1558,
        0.1547,
        0.1543,
        0.1541,
        0.1636,
        0.1574,
        0.1548,
        0.1545,
        0.1565,
        0.155,
        0.1642,
        0.1559,
        0.1545,
        0.1559,
        0.155,
        0.1539,
        0.1629,
        0.1565,
        0.1542,
        0.1542,
        0.1537,
        0.1539,
        0.1593,
        0.1561,
        0.1543,
        0.1546,
        0.155,
        0.1542,
        0.1527,
        0.156,
        0.153,
        0.1557,
        0.1539,
        0.1537,
        0.1532,
        0.1648,
        0.1554,
        0.1542,
        0.1546,
        0.1549,
        0.1543,
        0.1637,
        0.155,
        0.1539
      ],
      "adapter": "torch_compile",
      "display_name": "PyTorch Compile"
    },
    "pyc": {
      "status": "unavailable",
      "reason": "PyC CUDA backend is not implemented yet; current PyC benchmark command is CPU-only",
      "adapter": "pyc",
      "display_name": "PyC CUDA"
    },
    "tvm": {
      "status": "unavailable",
      "reason": "TVM not installed; install TVM or change TVM_BENCH_CMD",
      "adapter": "tvm",
      "display_name": "TVM"
    },
    "xla": {
      "status": "unavailable",
      "reason": "torch_xla not installed; install torch_xla or change XLA_BENCH_CMD",
      "adapter": "xla",
      "display_name": "XLA"
    },
    "tensorrt": {
      "status": "unavailable",
      "reason": "torch_tensorrt not installed; install it or change TENSORRT_BENCH_CMD",
      "adapter": "tensorrt",
      "display_name": "TensorRT"
    },
    "glow": {
      "status": "unavailable",
      "reason": "Glow runtime benchmark integration is not wired in this environment yet",
      "adapter": "glow",
      "display_name": "Glow"
    }
  }
}
