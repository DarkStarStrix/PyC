{
  "meta": {
    "timestamp_utc": "2026-02-18T01:15:33.786564+00:00",
    "host": "90c892d22de7",
    "os": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35",
    "python": "3.11.11",
    "device": "cpu",
    "batch": 64,
    "hidden": 2048,
    "iters": 30,
    "warmup": 10,
    "tag": "full_cpu_all_v4",
    "adapters": [
      "torch_eager",
      "torch_compile",
      "pyc",
      "tvm",
      "xla",
      "tensorrt",
      "glow"
    ]
  },
  "gpu": {
    "available": true,
    "gpus": [
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      },
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      }
    ]
  },
  "adapters": {
    "torch_eager": {
      "status": "ok",
      "backend": "torch_eager",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 30,
      "warmup": 10,
      "latency_ms": {
        "mean": 36.2089,
        "p50": 15.9215,
        "p95": 73.9385,
        "min": 13.9972,
        "max": 76.0297
      },
      "throughput_tokens_per_sec": 3619888.08,
      "peak_memory_bytes": 0,
      "samples_ms": [
        71.9603,
        14.6317,
        14.4792,
        71.4604,
        14.3107,
        14.5035,
        69.72,
        14.8332,
        15.8938,
        76.0297,
        15.6368,
        71.5103,
        17.9009,
        18.4001,
        70.8914,
        15.0271,
        73.9385,
        15.9215,
        14.2333,
        72.2051,
        17.3563,
        15.4605,
        72.4923,
        16.9499,
        14.6277,
        71.9133,
        13.9972,
        14.8972,
        70.7552,
        14.3284
      ],
      "adapter": "torch_eager",
      "display_name": "PyTorch Eager"
    },
    "torch_compile": {
      "status": "ok",
      "backend": "torch_compile",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 30,
      "warmup": 10,
      "latency_ms": {
        "mean": 26.4611,
        "p50": 10.3385,
        "p95": 71.5978,
        "min": 9.976,
        "max": 73.5017
      },
      "throughput_tokens_per_sec": 4953391.43,
      "peak_memory_bytes": 0,
      "samples_ms": [
        10.0278,
        69.4358,
        12.9572,
        9.9848,
        10.1827,
        70.2154,
        10.1263,
        10.0194,
        10.0477,
        73.5017,
        10.2117,
        10.1494,
        10.0652,
        68.3047,
        10.3385,
        10.1774,
        9.976,
        71.5978,
        10.1256,
        10.3787,
        70.1497,
        10.3417,
        10.4476,
        10.4133,
        70.3537,
        13.0132,
        10.1861,
        10.3684,
        70.4295,
        10.305
      ],
      "adapter": "torch_compile",
      "display_name": "PyTorch Compile"
    },
    "pyc": {
      "status": "ok",
      "backend": "pyc_cpu_microbench",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 30,
      "warmup": 10,
      "latency_ms": {
        "mean": 141.0321,
        "p50": 139.8214,
        "p95": 152.4895,
        "min": 130.3579,
        "max": 152.8856
      },
      "throughput_tokens_per_sec": 929377.29,
      "peak_memory_bytes": 0,
      "note": "PyC benchmark currently executes deterministic CPU path; CUDA mode is a stub fallback.",
      "adapter": "pyc",
      "display_name": "PyC CUDA"
    },
    "tvm": {
      "status": "ok",
      "backend": "tvm",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 30,
      "warmup": 10,
      "latency_ms": {
        "mean": 23.6425,
        "p50": 9.98,
        "p95": 69.3122,
        "min": 9.6471,
        "max": 69.687
      },
      "throughput_tokens_per_sec": 5543914.26,
      "peak_memory_bytes": 0,
      "note": "",
      "adapter": "tvm",
      "display_name": "TVM"
    },
    "xla": {
      "status": "ok",
      "backend": "xla_proxy_torch",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 30,
      "warmup": 10,
      "latency_ms": {
        "mean": 38.9585,
        "p50": 16.9793,
        "p95": 76.5611,
        "min": 13.4725,
        "max": 77.9512
      },
      "throughput_tokens_per_sec": 3364402.13,
      "peak_memory_bytes": 0,
      "note": "torch_xla path unavailable; executed deterministic torch proxy workload.",
      "adapter": "xla",
      "display_name": "XLA"
    },
    "tensorrt": {
      "status": "ok",
      "backend": "tensorrt_proxy_torch_compile",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 30,
      "warmup": 10,
      "latency_ms": {
        "mean": 31.2176,
        "p50": 13.5502,
        "p95": 75.9196,
        "min": 12.3553,
        "max": 76.257
      },
      "throughput_tokens_per_sec": 4198661.45,
      "peak_memory_bytes": 0,
      "note": "TensorRT is CUDA-only; executed deterministic torch.compile proxy on CPU.",
      "adapter": "tensorrt",
      "display_name": "TensorRT"
    },
    "glow": {
      "status": "ok",
      "backend": "glow_proxy",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 30,
      "warmup": 10,
      "latency_ms": {
        "mean": 33.41,
        "p50": 14.4597,
        "p95": 73.7702,
        "min": 12.9364,
        "max": 74.357
      },
      "throughput_tokens_per_sec": 3923135.71,
      "peak_memory_bytes": 0,
      "note": "Glow runtime is not linked in this environment; this is a deterministic proxy workload.",
      "adapter": "glow",
      "display_name": "Glow"
    }
  }
}
