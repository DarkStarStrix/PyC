{
  "meta": {
    "timestamp_utc": "2026-02-18T00:46:15.206732+00:00",
    "host": "90c892d22de7",
    "os": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35",
    "python": "3.11.11",
    "device": "cpu",
    "batch": 64,
    "hidden": 2048,
    "iters": 80,
    "warmup": 20,
    "tag": "host89_cpu_compare",
    "adapters": [
      "torch_eager",
      "torch_compile",
      "pyc",
      "tvm",
      "xla",
      "tensorrt",
      "glow"
    ]
  },
  "gpu": {
    "available": true,
    "gpus": [
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      },
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      }
    ]
  },
  "adapters": {
    "torch_eager": {
      "status": "ok",
      "backend": "torch_eager",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 80,
      "warmup": 20,
      "latency_ms": {
        "mean": 33.9212,
        "p50": 15.3394,
        "p95": 73.9333,
        "min": 11.6989,
        "max": 80.0062
      },
      "throughput_tokens_per_sec": 3864010.47,
      "peak_memory_bytes": 0,
      "samples_ms": [
        15.9271,
        80.0062,
        16.0288,
        72.6912,
        15.2701,
        13.8087,
        72.4658,
        15.4803,
        13.582,
        70.5228,
        13.7629,
        14.3816,
        73.2179,
        15.6854,
        15.3343,
        67.6236,
        15.2804,
        14.5365,
        70.2111,
        15.7141,
        14.4662,
        70.9128,
        16.5259,
        13.976,
        74.5139,
        13.7085,
        13.4124,
        73.3186,
        20.3444,
        13.208,
        68.5023,
        12.5758,
        12.7343,
        72.2807,
        13.3317,
        12.8384,
        73.5907,
        13.3844,
        12.5848,
        71.3702,
        12.7937,
        12.4352,
        73.0322,
        13.1265,
        11.6989,
        70.8156,
        12.166,
        12.2712,
        13.0488,
        73.8029,
        13.0554,
        13.1989,
        73.9333,
        18.024,
        72.3771,
        14.245,
        13.8361,
        71.8703,
        19.3322,
        13.9021,
        73.7206,
        13.9813,
        13.5359,
        71.7079,
        13.94,
        13.7787,
        75.8535,
        15.9879,
        14.8288,
        67.3488,
        14.6462,
        75.5425,
        20.1785,
        15.3394,
        67.3378,
        15.2501,
        15.3706,
        68.9581,
        14.3852,
        13.9305
      ],
      "adapter": "torch_eager",
      "display_name": "PyTorch Eager"
    },
    "torch_compile": {
      "status": "ok",
      "backend": "torch_compile",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 80,
      "warmup": 20,
      "latency_ms": {
        "mean": 24.8649,
        "p50": 9.9002,
        "p95": 71.4869,
        "min": 8.9827,
        "max": 75.2746
      },
      "throughput_tokens_per_sec": 5271375.11,
      "peak_memory_bytes": 0,
      "samples_ms": [
        69.9146,
        13.02,
        9.5983,
        9.7998,
        68.1565,
        9.9935,
        9.8631,
        9.8677,
        69.762,
        12.7083,
        9.707,
        9.8548,
        68.3393,
        9.8888,
        9.8964,
        9.8416,
        68.9724,
        16.8089,
        9.9075,
        9.8845,
        69.2284,
        9.1685,
        9.0298,
        9.0779,
        67.2561,
        11.813,
        9.307,
        9.0848,
        69.0981,
        9.3266,
        9.1745,
        9.0262,
        9.1585,
        71.7115,
        9.2238,
        9.1159,
        9.0205,
        69.1302,
        9.8943,
        9.0527,
        9.0898,
        68.2327,
        9.1073,
        9.0993,
        9.1602,
        9.2324,
        71.4869,
        9.0233,
        9.0778,
        8.9827,
        68.121,
        9.1627,
        9.2021,
        9.1316,
        68.5757,
        11.7717,
        9.0409,
        9.1636,
        9.9608,
        68.9519,
        9.9569,
        9.9002,
        9.9458,
        75.2746,
        10.5322,
        9.9348,
        70.2185,
        9.9613,
        10.007,
        9.9065,
        73.0777,
        9.8843,
        9.8933,
        9.8709,
        68.9145,
        9.9521,
        9.9692,
        9.9408,
        72.6252,
        11.1659
      ],
      "adapter": "torch_compile",
      "display_name": "PyTorch Compile"
    },
    "pyc": {
      "status": "ok",
      "backend": "pyc_cpu_microbench",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 80,
      "warmup": 20,
      "latency_ms": {
        "mean": 142.277,
        "p50": 141.5733,
        "p95": 148.8281,
        "min": 129.6121,
        "max": 160.0102
      },
      "throughput_tokens_per_sec": 921244.9,
      "peak_memory_bytes": 0,
      "note": "PyC benchmark currently exercises CPU path only.",
      "adapter": "pyc",
      "display_name": "PyC CUDA"
    },
    "tvm": {
      "status": "unavailable",
      "reason": "TVM not installed; install TVM or change TVM_BENCH_CMD",
      "adapter": "tvm",
      "display_name": "TVM"
    },
    "xla": {
      "status": "unavailable",
      "reason": "torch_xla not installed; install torch_xla or change XLA_BENCH_CMD",
      "adapter": "xla",
      "display_name": "XLA"
    },
    "tensorrt": {
      "status": "unavailable",
      "reason": "torch_tensorrt not installed; install it or change TENSORRT_BENCH_CMD",
      "adapter": "tensorrt",
      "display_name": "TensorRT"
    },
    "glow": {
      "status": "unavailable",
      "reason": "Glow runtime benchmark integration is not wired in this environment yet",
      "adapter": "glow",
      "display_name": "Glow"
    }
  }
}
