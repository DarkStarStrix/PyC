# GPU Benchmark Suite

- Timestamp (UTC): 2026-02-18T02:34:26.541928+00:00
- Host: 90c892d22de7
- OS: Linux-6.8.0-85-generic-x86_64-with-glibc2.35
- Python: 3.11.11

## GPU

- GPU 1: NVIDIA GeForce RTX 4090 | driver 570.195.03 | mem 24564 MiB | cc 8.9
- GPU 2: NVIDIA GeForce RTX 4090 | driver 570.195.03 | mem 24564 MiB | cc 8.9

## Adapter Results

- `PyTorch Eager` [native]: p50 0.1135 ms, p95 0.1285 ms, mean 0.1154 ms, throughput 1135905416.11 tokens/s
- `PyTorch Compile` [native]: p50 0.1544 ms, p95 0.1665 ms, mean 0.1551 ms, throughput 844896466.85 tokens/s
- `PyC CUDA` [proxy]: p50 25.383 ms, p95 27.327 ms, mean 25.5228 ms, throughput 5135486.7 tokens/s
- `TVM`: unavailable (TVM not installed; install TVM or change TVM_BENCH_CMD)
- `XLA` [proxy]: p50 0.1138 ms, p95 0.1263 ms, mean 0.1157 ms, throughput 1133048992.77 tokens/s
- `TensorRT` [proxy]: p50 0.156 ms, p95 0.1743 ms, mean 0.1598 ms, throughput 820055823.27 tokens/s
- `Glow` [proxy]: p50 0.119 ms, p95 0.1332 ms, mean 0.1314 ms, throughput 997355892.15 tokens/s

## Notes

- Adapters are normalized to a common JSON schema.
- For TVM/XLA/TensorRT/PyC custom paths, configure `*_BENCH_CMD` env vars in each adapter.
