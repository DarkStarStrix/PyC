{
  "meta": {
    "timestamp_utc": "2026-02-17T23:34:56.960815+00:00",
    "host": "b5060ab798c6",
    "os": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35",
    "python": "3.11.11",
    "device": "cuda",
    "batch": 64,
    "hidden": 2048,
    "iters": 80,
    "warmup": 20,
    "tag": "gpu_compare_all",
    "adapters": [
      "torch_eager",
      "torch_compile",
      "pyc",
      "tvm",
      "xla",
      "tensorrt",
      "glow"
    ]
  },
  "gpu": {
    "available": true,
    "gpus": [
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      }
    ]
  },
  "adapters": {
    "torch_eager": {
      "status": "ok",
      "backend": "torch_eager",
      "device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 80,
      "warmup": 20,
      "latency_ms": {
        "mean": 0.11,
        "p50": 0.1087,
        "p95": 0.1179,
        "min": 0.1063,
        "max": 0.125
      },
      "throughput_tokens_per_sec": 1191471592.77,
      "peak_memory_bytes": 78541312,
      "samples_ms": [
        0.1099,
        0.1127,
        0.1103,
        0.1093,
        0.1101,
        0.1176,
        0.1129,
        0.1095,
        0.1099,
        0.1112,
        0.1094,
        0.1088,
        0.1087,
        0.1101,
        0.125,
        0.1091,
        0.1087,
        0.1077,
        0.1083,
        0.1073,
        0.1077,
        0.1077,
        0.1079,
        0.1231,
        0.108,
        0.1083,
        0.1082,
        0.108,
        0.1077,
        0.1093,
        0.1077,
        0.1179,
        0.1119,
        0.1099,
        0.1072,
        0.1075,
        0.1084,
        0.1131,
        0.1094,
        0.1086,
        0.1207,
        0.11,
        0.1075,
        0.109,
        0.1074,
        0.1072,
        0.1091,
        0.1076,
        0.1071,
        0.1249,
        0.1073,
        0.1086,
        0.1077,
        0.1073,
        0.1063,
        0.1075,
        0.1067,
        0.1169,
        0.1117,
        0.1083,
        0.107,
        0.1072,
        0.1074,
        0.1076,
        0.1082,
        0.1075,
        0.1176,
        0.1093,
        0.1085,
        0.1082,
        0.1113,
        0.1079,
        0.1095,
        0.1095,
        0.1076,
        0.1176,
        0.1089,
        0.1086,
        0.1099,
        0.1089
      ],
      "adapter": "torch_eager",
      "display_name": "PyTorch Eager"
    },
    "torch_compile": {
      "status": "ok",
      "backend": "torch_compile",
      "device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 80,
      "warmup": 20,
      "latency_ms": {
        "mean": 0.1463,
        "p50": 0.1446,
        "p95": 0.1547,
        "min": 0.1424,
        "max": 0.1795
      },
      "throughput_tokens_per_sec": 896015628.38,
      "peak_memory_bytes": 187326464,
      "samples_ms": [
        0.1549,
        0.1461,
        0.1455,
        0.1437,
        0.1486,
        0.1465,
        0.146,
        0.159,
        0.145,
        0.1437,
        0.1457,
        0.1465,
        0.1442,
        0.1547,
        0.1463,
        0.147,
        0.1453,
        0.1441,
        0.1438,
        0.1458,
        0.1464,
        0.1464,
        0.1443,
        0.1465,
        0.144,
        0.144,
        0.1527,
        0.1465,
        0.1471,
        0.1461,
        0.1443,
        0.1456,
        0.1528,
        0.1458,
        0.1434,
        0.1446,
        0.1442,
        0.144,
        0.1446,
        0.1562,
        0.1453,
        0.1443,
        0.1438,
        0.1446,
        0.1452,
        0.1504,
        0.1445,
        0.1443,
        0.1433,
        0.1443,
        0.1449,
        0.1436,
        0.1795,
        0.1469,
        0.1437,
        0.1445,
        0.1442,
        0.1438,
        0.1503,
        0.1446,
        0.1435,
        0.1444,
        0.143,
        0.143,
        0.1434,
        0.1534,
        0.1432,
        0.1443,
        0.1447,
        0.1444,
        0.1424,
        0.1483,
        0.1462,
        0.1443,
        0.1438,
        0.1432,
        0.1426,
        0.1432,
        0.1502,
        0.1432
      ],
      "adapter": "torch_compile",
      "display_name": "PyTorch Compile"
    },
    "pyc": {
      "status": "unavailable",
      "reason": "Set PYC_GPU_BENCH_CMD to a command that outputs benchmark JSON for PyC CUDA path",
      "adapter": "pyc",
      "display_name": "PyC CUDA"
    },
    "tvm": {
      "status": "unavailable",
      "reason": "Install TVM or set TVM_BENCH_CMD to external benchmark command",
      "adapter": "tvm",
      "display_name": "TVM"
    },
    "xla": {
      "status": "unavailable",
      "reason": "Install torch_xla or set XLA_BENCH_CMD to external benchmark command",
      "adapter": "xla",
      "display_name": "XLA"
    },
    "tensorrt": {
      "status": "unavailable",
      "reason": "Install TensorRT python bindings or set TENSORRT_BENCH_CMD",
      "adapter": "tensorrt",
      "display_name": "TensorRT"
    },
    "glow": {
      "status": "unavailable",
      "reason": "Set GLOW_BENCH_CMD to external benchmark command for Glow",
      "adapter": "glow",
      "display_name": "Glow"
    }
  }
}
