# GPU Benchmark Suite

- Timestamp (UTC): 2026-02-18T01:20:07.606203+00:00
- Host: 90c892d22de7
- OS: Linux-6.8.0-85-generic-x86_64-with-glibc2.35
- Python: 3.11.11

## GPU

- GPU 1: NVIDIA GeForce RTX 4090 | driver 570.195.03 | mem 24564 MiB | cc 8.9
- GPU 2: NVIDIA GeForce RTX 4090 | driver 570.195.03 | mem 24564 MiB | cc 8.9

## Adapter Results

- `PyTorch Eager`: p50 15.795 ms, p95 73.8275 ms, mean 36.9792 ms, throughput 3544482.38 tokens/s
- `PyTorch Compile`: p50 10.102 ms, p95 72.0898 ms, mean 25.2958 ms, throughput 5181578.06 tokens/s
- `PyC CUDA`: p50 140.6058 ms, p95 146.6984 ms, mean 140.8895 ms, throughput 930317.61 tokens/s
- `TVM`: p50 10.515 ms, p95 69.6808 ms, mean 25.6445 ms, throughput 5111115.19 tokens/s
- `XLA`: p50 18.148 ms, p95 76.627 ms, mean 38.1398 ms, throughput 3436615.64 tokens/s
- `TensorRT`: p50 13.5051 ms, p95 73.1313 ms, mean 32.5161 ms, throughput 4030982.76 tokens/s
- `Glow`: p50 15.8427 ms, p95 73.3043 ms, mean 35.5197 ms, throughput 3690120.45 tokens/s

## Notes

- Adapters are normalized to a common JSON schema.
- For TVM/XLA/TensorRT/PyC custom paths, configure `*_BENCH_CMD` env vars in each adapter.
