# GPU Benchmark Suite

- Timestamp (UTC): 2026-02-18T01:20:47.810820+00:00
- Host: 90c892d22de7
- OS: Linux-6.8.0-85-generic-x86_64-with-glibc2.35
- Python: 3.11.11

## GPU

- GPU 1: NVIDIA GeForce RTX 4090 | driver 570.195.03 | mem 24564 MiB | cc 8.9
- GPU 2: NVIDIA GeForce RTX 4090 | driver 570.195.03 | mem 24564 MiB | cc 8.9

## Adapter Results

- `PyTorch Eager`: p50 0.1171 ms, p95 0.1275 ms, mean 0.1184 ms, throughput 1106563375.79 tokens/s
- `PyTorch Compile`: p50 0.1598 ms, p95 0.171 ms, mean 0.1604 ms, throughput 816905665.59 tokens/s
- `PyC CUDA`: p50 147.8003 ms, p95 152.0208 ms, mean 146.3051 ms, throughput 895881.02 tokens/s
- `TVM`: p50 10.0789 ms, p95 69.3395 ms, mean 24.7123 ms, throughput 5303906.98 tokens/s
- `XLA`: p50 0.1253 ms, p95 0.1507 ms, mean 0.1263 ms, throughput 1037486165.78 tokens/s
- `TensorRT`: p50 0.171 ms, p95 0.4429 ms, mean 0.2134 ms, throughput 614332341.9 tokens/s
- `Glow`: p50 0.1157 ms, p95 0.134 ms, mean 0.1186 ms, throughput 1105361407.6 tokens/s

## Notes

- Adapters are normalized to a common JSON schema.
- For TVM/XLA/TensorRT/PyC custom paths, configure `*_BENCH_CMD` env vars in each adapter.
