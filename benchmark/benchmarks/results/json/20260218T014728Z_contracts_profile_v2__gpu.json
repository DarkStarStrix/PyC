{
  "meta": {
    "timestamp_utc": "2026-02-18T01:48:58.301294+00:00",
    "host": "90c892d22de7",
    "os": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35",
    "python": "3.11.11",
    "device": "cuda",
    "batch": 64,
    "hidden": 2048,
    "iters": 40,
    "warmup": 10,
    "tag": "gpu",
    "adapters": [
      "torch_eager",
      "torch_compile",
      "pyc",
      "tvm",
      "xla",
      "tensorrt",
      "glow"
    ],
    "run_id": "20260218T014728Z_contracts_profile_v2",
    "git_head": "c5d8438",
    "git_dirty": 1
  },
  "gpu": {
    "available": true,
    "gpus": [
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      },
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      }
    ]
  },
  "adapters": {
    "torch_eager": {
      "status": "ok",
      "backend": "torch_eager",
      "device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 0.1113,
        "p50": 0.1098,
        "p95": 0.1237,
        "min": 0.108,
        "max": 0.126
      },
      "throughput_tokens_per_sec": 1177409204.73,
      "peak_memory_bytes": 79327744,
      "samples_ms": [
        0.1249,
        0.116,
        0.1111,
        0.1109,
        0.1083,
        0.1092,
        0.1104,
        0.1087,
        0.1105,
        0.1237,
        0.11,
        0.1085,
        0.1096,
        0.1083,
        0.108,
        0.1097,
        0.1092,
        0.1177,
        0.1133,
        0.1101,
        0.1095,
        0.1101,
        0.1098,
        0.1097,
        0.1085,
        0.1098,
        0.126,
        0.1104,
        0.11,
        0.1093,
        0.1093,
        0.1081,
        0.1089,
        0.1088,
        0.1172,
        0.1129,
        0.1099,
        0.1095,
        0.1087,
        0.1084
      ],
      "adapter": "torch_eager",
      "display_name": "PyTorch Eager"
    },
    "torch_compile": {
      "status": "ok",
      "backend": "torch_compile",
      "device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 0.1619,
        "p50": 0.1543,
        "p95": 0.1734,
        "min": 0.151,
        "max": 0.2557
      },
      "throughput_tokens_per_sec": 809775992.05,
      "peak_memory_bytes": 78280192,
      "samples_ms": [
        0.2557,
        0.254,
        0.1725,
        0.1615,
        0.1734,
        0.1615,
        0.1576,
        0.1573,
        0.1575,
        0.1574,
        0.1688,
        0.1591,
        0.1547,
        0.1543,
        0.1532,
        0.1544,
        0.1662,
        0.1575,
        0.1543,
        0.1532,
        0.1521,
        0.154,
        0.1528,
        0.1585,
        0.1537,
        0.154,
        0.1524,
        0.1533,
        0.1523,
        0.1718,
        0.1532,
        0.152,
        0.1517,
        0.151,
        0.1515,
        0.1662,
        0.1524,
        0.1519,
        0.1534,
        0.1525
      ],
      "adapter": "torch_compile",
      "display_name": "PyTorch Compile"
    },
    "pyc": {
      "status": "ok",
      "backend": "pyc_compiler_next",
      "device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 1101.8633,
        "p50": 1070.001,
        "p95": 1199.584,
        "min": 1054.604,
        "max": 1224.143
      },
      "throughput_tokens_per_sec": 118954.86,
      "peak_memory_bytes": 17825792,
      "profile": {
        "dispatch_ms_mean": 1101.83,
        "graph_exec_ms_mean": 1101.83,
        "controller_ms_mean": 0.0013,
        "kernel_select_ms_mean": 0.0028
      },
      "note": "PyC benchmark uses compiler-next API path; CUDA currently executes deterministic fallback until native kernels land.",
      "adapter": "pyc",
      "display_name": "PyC CUDA"
    },
    "tvm": {
      "status": "ok",
      "backend": "tvm",
      "device": "cpu",
      "requested_device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 24.8347,
        "p50": 10.2136,
        "p95": 69.3832,
        "min": 9.91,
        "max": 69.4516
      },
      "throughput_tokens_per_sec": 5277766.16,
      "peak_memory_bytes": 0,
      "note": "TVM CUDA target unavailable; benchmark executed on TVM CPU fallback.",
      "adapter": "tvm",
      "display_name": "TVM"
    },
    "xla": {
      "status": "ok",
      "backend": "xla_proxy_torch",
      "device": "cuda",
      "requested_device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 0.1113,
        "p50": 0.1105,
        "p95": 0.1146,
        "min": 0.1082,
        "max": 0.122
      },
      "throughput_tokens_per_sec": 1177730901.64,
      "peak_memory_bytes": 79327744,
      "note": "torch_xla path unavailable; executed deterministic torch proxy workload.",
      "adapter": "xla",
      "display_name": "XLA"
    },
    "tensorrt": {
      "status": "ok",
      "backend": "tensorrt_proxy_torch_compile",
      "device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 0.1697,
        "p50": 0.1683,
        "p95": 0.1818,
        "min": 0.1642,
        "max": 0.1824
      },
      "throughput_tokens_per_sec": 772206057.46,
      "peak_memory_bytes": 78541312,
      "note": "torch_tensorrt unavailable; executed torch.compile proxy workload.",
      "adapter": "tensorrt",
      "display_name": "TensorRT"
    },
    "glow": {
      "status": "ok",
      "backend": "glow_proxy",
      "device": "cuda",
      "requested_device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 0.118,
        "p50": 0.1091,
        "p95": 0.1254,
        "min": 0.1077,
        "max": 0.3867
      },
      "throughput_tokens_per_sec": 1110418890.83,
      "peak_memory_bytes": 79327744,
      "note": "Glow runtime is not linked in this environment; this is a deterministic proxy workload.",
      "adapter": "glow",
      "display_name": "Glow"
    }
  }
}
