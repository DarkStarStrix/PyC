{
  "meta": {
    "timestamp_utc": "2026-02-18T02:01:15.498702+00:00",
    "host": "90c892d22de7",
    "os": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35",
    "python": "3.11.11",
    "device": "cpu",
    "batch": 64,
    "hidden": 2048,
    "iters": 40,
    "warmup": 10,
    "tag": "cpu",
    "adapters": [
      "torch_eager",
      "torch_compile",
      "pyc",
      "tvm",
      "xla",
      "tensorrt",
      "glow"
    ],
    "run_id": "20260218T020115Z_phase_impl_v1",
    "git_head": "c5d8438",
    "git_dirty": 1
  },
  "gpu": {
    "available": true,
    "gpus": [
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      },
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      }
    ]
  },
  "adapters": {
    "torch_eager": {
      "status": "ok",
      "backend": "torch_eager",
      "mode": "native",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 36.7279,
        "p50": 16.5592,
        "p95": 76.1947,
        "min": 12.709,
        "max": 81.6557
      },
      "throughput_tokens_per_sec": 3568730.16,
      "peak_memory_bytes": 0,
      "samples_ms": [
        70.7266,
        12.709,
        13.1947,
        72.2657,
        18.2721,
        13.5918,
        70.5121,
        14.0083,
        13.0268,
        70.8873,
        16.3977,
        15.3079,
        70.8946,
        15.284,
        14.9085,
        69.3767,
        14.3728,
        14.2953,
        74.1937,
        16.5592,
        14.4703,
        70.6864,
        14.425,
        15.1143,
        77.3709,
        16.9799,
        71.6747,
        16.5585,
        81.6557,
        17.5087,
        16.6688,
        76.1947,
        15.6549,
        14.3889,
        68.1142,
        15.1578,
        14.6976,
        75.5808,
        15.217,
        70.2126
      ],
      "adapter": "torch_eager",
      "display_name": "PyTorch Eager"
    },
    "torch_compile": {
      "status": "ok",
      "backend": "torch_compile",
      "mode": "native",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 25.3152,
        "p50": 10.7323,
        "p95": 70.709,
        "min": 8.7472,
        "max": 73.584
      },
      "throughput_tokens_per_sec": 5177599.72,
      "peak_memory_bytes": 0,
      "samples_ms": [
        9.1048,
        9.2034,
        9.1881,
        69.1328,
        9.2334,
        9.2328,
        9.2688,
        71.7549,
        8.9824,
        9.207,
        9.0914,
        69.2412,
        8.9419,
        9.305,
        8.7472,
        69.0664,
        13.801,
        10.3782,
        10.1412,
        70.108,
        10.5905,
        10.2865,
        10.357,
        73.584,
        10.3122,
        10.5309,
        69.7866,
        11.0932,
        10.9007,
        10.6949,
        70.0308,
        13.104,
        10.9038,
        11.149,
        68.8506,
        11.086,
        10.7326,
        70.709,
        14.0435,
        10.7323
      ],
      "adapter": "torch_compile",
      "display_name": "PyTorch Compile"
    },
    "pyc": {
      "status": "ok",
      "backend": "pyc_compiler_next",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 1080.387,
        "p50": 1068.399,
        "p95": 1133.616,
        "min": 1059.105,
        "max": 1142.051
      },
      "throughput_tokens_per_sec": 121319.49,
      "peak_memory_bytes": 17825792,
      "profile": {
        "dispatch_ms_mean": 1080.363,
        "graph_exec_ms_mean": 1080.363,
        "controller_ms_mean": 0.001,
        "kernel_select_ms_mean": 0.0025
      },
      "mode": "native",
      "note": "PyC benchmark uses compiler-next API path; CUDA currently executes deterministic fallback until native kernels land.",
      "adapter": "pyc",
      "display_name": "PyC CUDA"
    },
    "tvm": {
      "status": "ok",
      "backend": "tvm",
      "mode": "native",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 63.086,
        "p50": 82.076,
        "p95": 87.5437,
        "min": 22.9634,
        "max": 105.5203
      },
      "throughput_tokens_per_sec": 2077673.06,
      "peak_memory_bytes": 0,
      "note": "",
      "adapter": "tvm",
      "display_name": "TVM"
    },
    "xla": {
      "status": "ok",
      "backend": "xla_proxy_torch",
      "mode": "proxy",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 39.5868,
        "p50": 19.3143,
        "p95": 76.3604,
        "min": 13.3165,
        "max": 81.5946
      },
      "throughput_tokens_per_sec": 3311002.96,
      "peak_memory_bytes": 0,
      "note": "torch_xla path unavailable; executed deterministic torch proxy workload.",
      "adapter": "xla",
      "display_name": "XLA"
    },
    "tensorrt": {
      "status": "ok",
      "backend": "tensorrt_proxy_torch_compile",
      "mode": "proxy",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 25.2202,
        "p50": 10.1843,
        "p95": 70.0699,
        "min": 9.8996,
        "max": 73.1641
      },
      "throughput_tokens_per_sec": 5197095.92,
      "peak_memory_bytes": 0,
      "note": "TensorRT is CUDA-only; executed deterministic torch.compile proxy on CPU.",
      "adapter": "tensorrt",
      "display_name": "TensorRT"
    },
    "glow": {
      "status": "ok",
      "backend": "glow_proxy",
      "mode": "proxy",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 35.5114,
        "p50": 16.2324,
        "p95": 77.0203,
        "min": 14.374,
        "max": 79.8968
      },
      "throughput_tokens_per_sec": 3690981.62,
      "peak_memory_bytes": 0,
      "note": "Glow runtime is not linked in this environment; this is a deterministic proxy workload.",
      "adapter": "glow",
      "display_name": "Glow"
    }
  }
}
