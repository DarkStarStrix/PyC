{
  "meta": {
    "timestamp_utc": "2026-02-18T02:06:53.599453+00:00",
    "host": "90c892d22de7",
    "os": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35",
    "python": "3.11.11",
    "device": "cpu",
    "batch": 64,
    "hidden": 2048,
    "iters": 40,
    "warmup": 10,
    "tag": "cpu",
    "adapters": [
      "torch_eager",
      "torch_compile",
      "pyc",
      "tvm",
      "xla",
      "tensorrt",
      "glow"
    ],
    "run_id": "20260218T020653Z_phase_impl_v2",
    "git_head": "c5d8438",
    "git_dirty": 1
  },
  "gpu": {
    "available": true,
    "gpus": [
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      },
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      }
    ]
  },
  "adapters": {
    "torch_eager": {
      "status": "ok",
      "backend": "torch_eager",
      "mode": "native",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 34.6332,
        "p50": 14.5852,
        "p95": 73.8403,
        "min": 12.9528,
        "max": 81.1924
      },
      "throughput_tokens_per_sec": 3784576.88,
      "peak_memory_bytes": 0,
      "samples_ms": [
        72.5927,
        16.632,
        14.2762,
        72.6655,
        14.9376,
        13.5385,
        73.6604,
        13.8331,
        15.3671,
        71.9065,
        13.6117,
        13.9542,
        72.6536,
        13.7063,
        13.3806,
        71.7606,
        13.184,
        13.6999,
        74.5618,
        13.5632,
        14.2295,
        70.2603,
        14.3751,
        12.9528,
        73.8403,
        13.3223,
        14.6392,
        71.564,
        14.3444,
        14.0848,
        71.3526,
        14.5395,
        13.6372,
        81.1924,
        14.8593,
        69.0561,
        14.4218,
        14.5852,
        70.7817,
        13.804
      ],
      "adapter": "torch_eager",
      "display_name": "PyTorch Eager"
    },
    "torch_compile": {
      "status": "ok",
      "backend": "torch_compile",
      "mode": "native",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 32.881,
        "p50": 13.9565,
        "p95": 73.861,
        "min": 13.2765,
        "max": 75.1654
      },
      "throughput_tokens_per_sec": 3986249.41,
      "peak_memory_bytes": 0,
      "samples_ms": [
        13.4358,
        72.1543,
        14.6739,
        13.9565,
        72.5044,
        13.6197,
        13.845,
        74.9398,
        13.9879,
        13.6406,
        73.3685,
        14.0164,
        13.5536,
        70.9685,
        13.8094,
        13.4786,
        73.861,
        13.7925,
        13.6583,
        71.5559,
        13.6729,
        13.5056,
        73.8545,
        13.7288,
        13.3924,
        70.9082,
        13.6978,
        15.8793,
        72.7385,
        13.747,
        13.6509,
        70.5002,
        13.9708,
        13.4439,
        75.1654,
        13.9054,
        13.4139,
        69.9468,
        14.0216,
        13.2765
      ],
      "adapter": "torch_compile",
      "display_name": "PyTorch Compile"
    },
    "pyc": {
      "status": "ok",
      "backend": "pyc_compiler_next",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 941.6049,
        "p50": 888.972,
        "p95": 1238.539,
        "min": 629.265,
        "max": 1396.71
      },
      "throughput_tokens_per_sec": 139200.64,
      "peak_memory_bytes": 17825792,
      "profile": {
        "dispatch_ms_mean": 941.5647,
        "graph_exec_ms_mean": 941.5647,
        "controller_ms_mean": 0.0019,
        "kernel_select_ms_mean": 0.0022
      },
      "mode": "native",
      "note": "PyC benchmark uses compiler-next API path; CUDA currently executes deterministic fallback until native kernels land.",
      "adapter": "pyc",
      "display_name": "PyC CUDA"
    },
    "tvm": {
      "status": "ok",
      "backend": "tvm",
      "mode": "native",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 62.6453,
        "p50": 81.9292,
        "p95": 95.3797,
        "min": 17.0719,
        "max": 97.777
      },
      "throughput_tokens_per_sec": 2092287.61,
      "peak_memory_bytes": 0,
      "note": "",
      "adapter": "tvm",
      "display_name": "TVM"
    },
    "xla": {
      "status": "ok",
      "backend": "xla_proxy_torch",
      "mode": "proxy",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 39.8538,
        "p50": 18.3213,
        "p95": 76.4649,
        "min": 13.9877,
        "max": 79.3998
      },
      "throughput_tokens_per_sec": 3288821.21,
      "peak_memory_bytes": 0,
      "note": "torch_xla path unavailable; executed deterministic torch proxy workload.",
      "adapter": "xla",
      "display_name": "XLA"
    },
    "tensorrt": {
      "status": "ok",
      "backend": "tensorrt_proxy_torch_compile",
      "mode": "proxy",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 23.2356,
        "p50": 9.8483,
        "p95": 68.7295,
        "min": 9.0302,
        "max": 70.2122
      },
      "throughput_tokens_per_sec": 5641006.61,
      "peak_memory_bytes": 0,
      "note": "TensorRT is CUDA-only; executed deterministic torch.compile proxy on CPU.",
      "adapter": "tensorrt",
      "display_name": "TensorRT"
    },
    "glow": {
      "status": "ok",
      "backend": "glow_proxy",
      "mode": "proxy",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 39.2014,
        "p50": 19.195,
        "p95": 76.1299,
        "min": 14.1578,
        "max": 77.2592
      },
      "throughput_tokens_per_sec": 3343558.07,
      "peak_memory_bytes": 0,
      "note": "Glow runtime is not linked in this environment; this is a deterministic proxy workload.",
      "adapter": "glow",
      "display_name": "Glow"
    }
  }
}
