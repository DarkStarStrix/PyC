{
  "meta": {
    "timestamp_utc": "2026-02-18T01:47:28.628866+00:00",
    "host": "90c892d22de7",
    "os": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35",
    "python": "3.11.11",
    "device": "cpu",
    "batch": 64,
    "hidden": 2048,
    "iters": 40,
    "warmup": 10,
    "tag": "cpu",
    "adapters": [
      "torch_eager",
      "torch_compile",
      "pyc",
      "tvm",
      "xla",
      "tensorrt",
      "glow"
    ],
    "run_id": "20260218T014728Z_contracts_profile_v2",
    "git_head": "c5d8438",
    "git_dirty": 1
  },
  "gpu": {
    "available": true,
    "gpus": [
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      },
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      }
    ]
  },
  "adapters": {
    "torch_eager": {
      "status": "ok",
      "backend": "torch_eager",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 36.0145,
        "p50": 16.3671,
        "p95": 75.1722,
        "min": 13.8608,
        "max": 76.8362
      },
      "throughput_tokens_per_sec": 3639425.85,
      "peak_memory_bytes": 0,
      "samples_ms": [
        18.464,
        16.306,
        74.423,
        16.0678,
        75.1722,
        16.3671,
        16.1406,
        76.8362,
        17.4532,
        72.9761,
        16.2146,
        15.4585,
        70.4323,
        16.0458,
        15.7891,
        74.1693,
        15.0354,
        14.568,
        75.3812,
        14.3478,
        72.2348,
        14.0251,
        13.8608,
        72.2728,
        15.8235,
        15.1042,
        71.5159,
        17.0884,
        15.0177,
        72.7757,
        22.3833,
        74.8887,
        16.3905,
        15.8447,
        73.3109,
        15.6471,
        14.4658,
        70.1714,
        14.7256,
        15.3837
      ],
      "adapter": "torch_eager",
      "display_name": "PyTorch Eager"
    },
    "torch_compile": {
      "status": "ok",
      "backend": "torch_compile",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 32.7525,
        "p50": 13.2568,
        "p95": 76.628,
        "min": 12.2478,
        "max": 80.4896
      },
      "throughput_tokens_per_sec": 4001894.65,
      "peak_memory_bytes": 0,
      "samples_ms": [
        13.0606,
        77.8704,
        13.0132,
        13.2453,
        69.7889,
        13.0707,
        15.0955,
        76.628,
        13.5586,
        72.0796,
        13.8062,
        12.7256,
        12.8473,
        73.8414,
        12.7214,
        74.4134,
        13.5372,
        13.2568,
        12.524,
        80.4896,
        12.9778,
        68.414,
        12.9179,
        12.9583,
        72.6846,
        18.6332,
        12.7826,
        70.7803,
        12.6534,
        12.6005,
        12.4897,
        74.3899,
        12.2478,
        12.499,
        69.9283,
        12.4874,
        12.4025,
        72.1826,
        13.8822,
        12.6139
      ],
      "adapter": "torch_compile",
      "display_name": "PyTorch Compile"
    },
    "pyc": {
      "status": "ok",
      "backend": "pyc_compiler_next",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 1072.2825,
        "p50": 1070.868,
        "p95": 1083.914,
        "min": 1061.653,
        "max": 1093.82
      },
      "throughput_tokens_per_sec": 122236.44,
      "peak_memory_bytes": 17825792,
      "profile": {
        "dispatch_ms_mean": 1072.2653,
        "graph_exec_ms_mean": 1072.2653,
        "controller_ms_mean": 0.0008,
        "kernel_select_ms_mean": 0.0019
      },
      "note": "PyC benchmark uses compiler-next API path; CUDA currently executes deterministic fallback until native kernels land.",
      "adapter": "pyc",
      "display_name": "PyC CUDA"
    },
    "tvm": {
      "status": "ok",
      "backend": "tvm",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 26.5001,
        "p50": 10.5717,
        "p95": 68.4926,
        "min": 10.2389,
        "max": 69.7539
      },
      "throughput_tokens_per_sec": 4946099.73,
      "peak_memory_bytes": 0,
      "note": "",
      "adapter": "tvm",
      "display_name": "TVM"
    },
    "xla": {
      "status": "ok",
      "backend": "xla_proxy_torch",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 39.9168,
        "p50": 19.6563,
        "p95": 75.7144,
        "min": 15.0821,
        "max": 83.3806
      },
      "throughput_tokens_per_sec": 3283631.07,
      "peak_memory_bytes": 0,
      "note": "torch_xla path unavailable; executed deterministic torch proxy workload.",
      "adapter": "xla",
      "display_name": "XLA"
    },
    "tensorrt": {
      "status": "ok",
      "backend": "tensorrt_proxy_torch_compile",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 29.3551,
        "p50": 12.105,
        "p95": 71.0655,
        "min": 9.4357,
        "max": 76.3532
      },
      "throughput_tokens_per_sec": 4465052.76,
      "peak_memory_bytes": 0,
      "note": "TensorRT is CUDA-only; executed deterministic torch.compile proxy on CPU.",
      "adapter": "tensorrt",
      "display_name": "TensorRT"
    },
    "glow": {
      "status": "ok",
      "backend": "glow_proxy",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 33.087,
        "p50": 14.3688,
        "p95": 75.3568,
        "min": 12.4798,
        "max": 79.1713
      },
      "throughput_tokens_per_sec": 3961435.53,
      "peak_memory_bytes": 0,
      "note": "Glow runtime is not linked in this environment; this is a deterministic proxy workload.",
      "adapter": "glow",
      "display_name": "Glow"
    }
  }
}
