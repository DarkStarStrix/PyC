{
  "meta": {
    "timestamp_utc": "2026-02-18T01:45:48.273077+00:00",
    "host": "90c892d22de7",
    "os": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35",
    "python": "3.11.11",
    "device": "cuda",
    "batch": 64,
    "hidden": 2048,
    "iters": 40,
    "warmup": 10,
    "tag": "gpu",
    "adapters": [
      "torch_eager",
      "torch_compile",
      "pyc",
      "tvm",
      "xla",
      "tensorrt",
      "glow"
    ],
    "run_id": "20260218T014514Z_contracts_profile_v1",
    "git_head": "c5d8438",
    "git_dirty": 1
  },
  "gpu": {
    "available": true,
    "gpus": [
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      },
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      }
    ]
  },
  "adapters": {
    "torch_eager": {
      "status": "ok",
      "backend": "torch_eager",
      "device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 0.1237,
        "p50": 0.1209,
        "p95": 0.1374,
        "min": 0.1193,
        "max": 0.1376
      },
      "throughput_tokens_per_sec": 1059554024.41,
      "peak_memory_bytes": 79327744,
      "samples_ms": [
        0.1371,
        0.1241,
        0.1217,
        0.1209,
        0.1193,
        0.1203,
        0.127,
        0.1194,
        0.1376,
        0.1224,
        0.1202,
        0.1205,
        0.1201,
        0.1208,
        0.1198,
        0.1374,
        0.1248,
        0.1211,
        0.1214,
        0.1205,
        0.1208,
        0.1222,
        0.1208,
        0.1328,
        0.1293,
        0.121,
        0.1197,
        0.1203,
        0.1213,
        0.1203,
        0.1202,
        0.1373,
        0.1214,
        0.1255,
        0.1202,
        0.1204,
        0.1207,
        0.1203,
        0.1199,
        0.1374
      ],
      "adapter": "torch_eager",
      "display_name": "PyTorch Eager"
    },
    "torch_compile": {
      "status": "ok",
      "backend": "torch_compile",
      "device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 0.1574,
        "p50": 0.1563,
        "p95": 0.1677,
        "min": 0.1511,
        "max": 0.177
      },
      "throughput_tokens_per_sec": 832923177.27,
      "peak_memory_bytes": 78280192,
      "samples_ms": [
        0.177,
        0.1648,
        0.1586,
        0.1583,
        0.1566,
        0.1576,
        0.1677,
        0.1593,
        0.1575,
        0.1566,
        0.1582,
        0.1537,
        0.1668,
        0.1563,
        0.1556,
        0.1573,
        0.1574,
        0.1526,
        0.168,
        0.1538,
        0.1537,
        0.1527,
        0.1533,
        0.1566,
        0.1639,
        0.1557,
        0.1535,
        0.1523,
        0.1548,
        0.1551,
        0.1621,
        0.1552,
        0.1532,
        0.1517,
        0.1511,
        0.1512,
        0.1519,
        0.1663,
        0.1539,
        0.1529
      ],
      "adapter": "torch_compile",
      "display_name": "PyTorch Compile"
    },
    "pyc": {
      "status": "error",
      "error": "CMake Error at CMakeLists.txt:77 (add_executable):\n  Cannot find source file:\n\n    /root/PyC/tests/compiler_next/test_deterministic_contracts.c\n\n  Tried extensions .c .C .c++ .cc .cpp .cxx .cu .mpp .m .M .mm .ixx .cppm .h\n  .hh .h++ .hm .hpp .hxx .in .txx .f .F .for .f77 .f90 .f95 .f03 .hip .ispc\nCall Stack (most recent call first):\n  CMakeLists.txt:107 (pyc_add_compiler_next_test)\n\n\nCMake Error at CMakeLists.txt:77 (add_executable):\n  No SOURCES given to target: pyc_compiler_next_test_deterministic_contracts\nCall Stack (most recent call first):\n  CMakeLists.txt:107 (pyc_add_compiler_next_test)\n\n\nCMake Generate step failed.  Build files cannot be regenerated correctly.",
      "adapter": "pyc",
      "display_name": "PyC CUDA"
    },
    "tvm": {
      "status": "ok",
      "backend": "tvm",
      "device": "cpu",
      "requested_device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 24.7732,
        "p50": 10.1429,
        "p95": 69.3693,
        "min": 9.7129,
        "max": 73.0364
      },
      "throughput_tokens_per_sec": 5290889.26,
      "peak_memory_bytes": 0,
      "note": "TVM CUDA target unavailable; benchmark executed on TVM CPU fallback.",
      "adapter": "tvm",
      "display_name": "TVM"
    },
    "xla": {
      "status": "ok",
      "backend": "xla_proxy_torch",
      "device": "cuda",
      "requested_device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 0.1111,
        "p50": 0.1096,
        "p95": 0.1192,
        "min": 0.1079,
        "max": 0.1253
      },
      "throughput_tokens_per_sec": 1179663297.56,
      "peak_memory_bytes": 79327744,
      "note": "torch_xla path unavailable; executed deterministic torch proxy workload.",
      "adapter": "xla",
      "display_name": "XLA"
    },
    "tensorrt": {
      "status": "ok",
      "backend": "tensorrt_proxy_torch_compile",
      "device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 0.1685,
        "p50": 0.1664,
        "p95": 0.1786,
        "min": 0.1603,
        "max": 0.179
      },
      "throughput_tokens_per_sec": 778081141.34,
      "peak_memory_bytes": 78541312,
      "note": "torch_tensorrt unavailable; executed torch.compile proxy workload.",
      "adapter": "tensorrt",
      "display_name": "TensorRT"
    },
    "glow": {
      "status": "ok",
      "backend": "glow_proxy",
      "device": "cuda",
      "requested_device": "cuda",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 0.1156,
        "p50": 0.1134,
        "p95": 0.1223,
        "min": 0.1119,
        "max": 0.1394
      },
      "throughput_tokens_per_sec": 1133584704.27,
      "peak_memory_bytes": 79327744,
      "note": "Glow runtime is not linked in this environment; this is a deterministic proxy workload.",
      "adapter": "glow",
      "display_name": "Glow"
    }
  }
}
