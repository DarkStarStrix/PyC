{
  "meta": {
    "timestamp_utc": "2026-02-18T01:22:44.480982+00:00",
    "host": "90c892d22de7",
    "os": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35",
    "python": "3.11.11",
    "device": "cpu",
    "batch": 64,
    "hidden": 2048,
    "iters": 40,
    "warmup": 10,
    "tag": "cpu",
    "adapters": [
      "torch_eager",
      "torch_compile",
      "pyc",
      "tvm",
      "xla",
      "tensorrt",
      "glow"
    ],
    "run_id": "20260218T012244Z_host89_v2",
    "git_head": "c5d8438",
    "git_dirty": 1
  },
  "gpu": {
    "available": true,
    "gpus": [
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      },
      {
        "name": "NVIDIA GeForce RTX 4090",
        "driver_version": "570.195.03",
        "memory_total": "24564 MiB",
        "compute_capability": "8.9"
      }
    ]
  },
  "adapters": {
    "torch_eager": {
      "status": "ok",
      "backend": "torch_eager",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 36.9826,
        "p50": 16.1717,
        "p95": 77.3977,
        "min": 11.9802,
        "max": 94.5013
      },
      "throughput_tokens_per_sec": 3544157.27,
      "peak_memory_bytes": 0,
      "samples_ms": [
        14.344,
        74.4937,
        13.7778,
        13.6889,
        70.4404,
        13.1437,
        13.3354,
        74.147,
        13.5927,
        13.684,
        70.9851,
        13.295,
        13.2557,
        74.5686,
        12.4561,
        12.1954,
        68.5136,
        13.2431,
        12.5278,
        71.7531,
        12.8129,
        12.3695,
        11.9802,
        74.3095,
        12.2702,
        12.4287,
        94.5013,
        71.7403,
        18.4137,
        18.4087,
        77.3977,
        19.055,
        81.0447,
        20.99,
        69.8355,
        15.9507,
        16.0987,
        74.8343,
        16.1717,
        71.2476
      ],
      "adapter": "torch_eager",
      "display_name": "PyTorch Eager"
    },
    "torch_compile": {
      "status": "ok",
      "backend": "torch_compile",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 24.7309,
        "p50": 9.6974,
        "p95": 72.9653,
        "min": 8.992,
        "max": 74.0422
      },
      "throughput_tokens_per_sec": 5299933.5,
      "peak_memory_bytes": 0,
      "samples_ms": [
        9.7719,
        74.0422,
        10.0598,
        9.8723,
        9.2585,
        67.3577,
        10.3219,
        9.8943,
        9.6549,
        70.2634,
        9.3764,
        9.6379,
        10.2861,
        73.708,
        9.1666,
        9.1675,
        9.3035,
        68.3081,
        9.5075,
        8.992,
        9.1011,
        68.7337,
        12.243,
        9.2218,
        9.0895,
        68.7431,
        10.3684,
        9.6607,
        9.3461,
        9.0917,
        67.3778,
        9.6974,
        9.2707,
        11.3489,
        72.9653,
        9.2975,
        9.3072,
        9.4107,
        67.6753,
        9.3348
      ],
      "adapter": "torch_compile",
      "display_name": "PyTorch Compile"
    },
    "pyc": {
      "status": "ok",
      "backend": "pyc_cpu_microbench",
      "device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 141.0577,
        "p50": 140.245,
        "p95": 148.7101,
        "min": 128.7661,
        "max": 153.9186
      },
      "throughput_tokens_per_sec": 929208.52,
      "peak_memory_bytes": 0,
      "note": "PyC benchmark currently executes deterministic CPU path; CUDA mode is a stub fallback.",
      "adapter": "pyc",
      "display_name": "PyC CUDA"
    },
    "tvm": {
      "status": "ok",
      "backend": "tvm",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 29.3689,
        "p50": 13.5227,
        "p95": 70.6271,
        "min": 9.865,
        "max": 71.1114
      },
      "throughput_tokens_per_sec": 4462948.94,
      "peak_memory_bytes": 0,
      "note": "",
      "adapter": "tvm",
      "display_name": "TVM"
    },
    "xla": {
      "status": "ok",
      "backend": "xla_proxy_torch",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 36.9306,
        "p50": 16.6186,
        "p95": 73.9017,
        "min": 13.6635,
        "max": 76.804
      },
      "throughput_tokens_per_sec": 3549140.25,
      "peak_memory_bytes": 0,
      "note": "torch_xla path unavailable; executed deterministic torch proxy workload.",
      "adapter": "xla",
      "display_name": "XLA"
    },
    "tensorrt": {
      "status": "ok",
      "backend": "tensorrt_proxy_torch_compile",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 24.5778,
        "p50": 9.6623,
        "p95": 69.9137,
        "min": 8.7772,
        "max": 72.8862
      },
      "throughput_tokens_per_sec": 5332936.81,
      "peak_memory_bytes": 0,
      "note": "TensorRT is CUDA-only; executed deterministic torch.compile proxy on CPU.",
      "adapter": "tensorrt",
      "display_name": "TensorRT"
    },
    "glow": {
      "status": "ok",
      "backend": "glow_proxy",
      "device": "cpu",
      "requested_device": "cpu",
      "batch": 64,
      "hidden": 2048,
      "iters": 40,
      "warmup": 10,
      "latency_ms": {
        "mean": 34.8783,
        "p50": 15.1214,
        "p95": 74.5309,
        "min": 13.2331,
        "max": 78.7579
      },
      "throughput_tokens_per_sec": 3757982.89,
      "peak_memory_bytes": 0,
      "note": "Glow runtime is not linked in this environment; this is a deterministic proxy workload.",
      "adapter": "glow",
      "display_name": "Glow"
    }
  }
}
