<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>PyC Downloads and Results</title>
  <link rel="stylesheet" href="./styles.css">
</head>
<body>
  <main class="container">
    <div class="top-bar">
      <p class="eyebrow">PyC Compiler Runtime</p>
      <button id="theme-toggle" type="button" class="theme-toggle" aria-label="Toggle color theme">Switch Theme</button>
    </div>
    <h1>Deterministic compiler rails for AI workloads</h1>
    <p class="subtext">
      PyC is a C/CMake compiler runtime project focused on reproducible CI, memory-backpressure control, and policy-driven execution decisions.
      This page publishes latest release downloads and benchmark evidence generated in-repo.
    </p>

    <section>
      <h2>Release</h2>
      <p class="section-text">
        Latest release page:
        <a id="release-link" href="#" target="_blank" rel="noopener noreferrer">open release details</a>
      </p>
      <p id="status" class="status">Loading release metadata...</p>
      <p class="section-text">Download binaries by platform:</p>
      <ul>
        <li>Linux: <a id="download-linux" href="https://github.com/DarkStarStrix/PyC/releases/latest/download/pyc-linux-x86_64.tar.gz">pyc-linux-x86_64.tar.gz</a></li>
        <li>macOS: <a id="download-macos" href="https://github.com/DarkStarStrix/PyC/releases/latest/download/pyc-macos-arm64.tar.gz">pyc-macos-arm64.tar.gz</a></li>
        <li>Windows: <a id="download-windows" href="https://github.com/DarkStarStrix/PyC/releases/latest/download/pyc-windows-x86_64.zip">pyc-windows-x86_64.zip</a></li>
      </ul>
    </section>

    <section>
      <h2>Build From Source</h2>
      <pre><code>cmake -S . -B build -D PYC_BUILD_COMPILER_NEXT=ON -D PYC_BUILD_COMPILER_NEXT_TESTS=ON
cmake --build build --parallel
ctest --test-dir build -C Release --output-on-failure
./build/pyc</code></pre>
    </section>

    <section>
      <h2>Benchmark Publication</h2>
      <p id="results-status" class="status">Loading benchmark publication data...</p>
      <p class="section-text">
        Current state: CPU-path PyC is competitive in this workload shape, while GPU-path PyC is still fallback/proxy-bound until native CUDA dispatch is consistently active.
      </p>
      <p class="section-text">
        Data files:
        <a href="./website/results/manifest.json" target="_blank" rel="noopener noreferrer">manifest.json</a>
        |
        <a href="./website/results/latest-summary.json" target="_blank" rel="noopener noreferrer">latest-summary.json</a>
      </p>

      <h3>Phase 4 CPU Summary</h3>
      <table>
        <thead>
          <tr>
            <th>Adapter</th>
            <th>Mode</th>
            <th>Mean (ms)</th>
            <th>P50 (ms)</th>
            <th>P95 (ms)</th>
            <th>Throughput</th>
          </tr>
        </thead>
        <tbody id="cpu-results-body"></tbody>
      </table>

      <h3>Phase 4 GPU Summary</h3>
      <table>
        <thead>
          <tr>
            <th>Adapter</th>
            <th>Mode</th>
            <th>Mean (ms)</th>
            <th>P50 (ms)</th>
            <th>P95 (ms)</th>
            <th>Throughput</th>
          </tr>
        </thead>
        <tbody id="gpu-results-body"></tbody>
      </table>

      <h3>Phase 4 Charts</h3>
      <p class="section-text">
        In this Phase 4 run, PyC on CPU-path reached 24.0459 ms mean latency, ahead of PyTorch Compile at 26.7237 ms and PyTorch Eager at 36.9971 ms for this benchmark shape.
      </p>
      <p class="section-text">
        On GPU, PyC is still operating in proxy/fallback behavior at 25.5228 ms while native baselines sit in sub-millisecond territory (for example PyTorch Eager at 0.1154 ms). This is a kernel-dispatch maturity issue rather than a deterministic-rails issue.
      </p>
      <p class="section-text">
        Architecture decisions: keep deterministic compile/runtime contracts, explicit fallback counters, and policy-driven runtime controls first; then harden native CUDA kernels and utilization-aware scheduling. Broader goal: a production-grade AI compiler runtime that combines deterministic behavior with high GPU utilization and aggressive memory-backpressure control. More CUDA-focused tests are coming soon.
      </p>

      <div class="chart-grid">
        <figure>
          <img id="latest-cpu-svg" src="./benchmark/benchmarks/results/remote_results/host89/images/20260218T023355Z_phase4_final__cpu.svg" alt="Phase 4 CPU benchmark chart" loading="lazy">
          <figcaption>Phase 4 CPU SVG</figcaption>
        </figure>
        <figure>
          <img id="latest-gpu-svg" src="./benchmark/benchmarks/results/remote_results/host89/images/20260218T023355Z_phase4_final__gpu.svg" alt="Phase 4 GPU benchmark chart" loading="lazy">
          <figcaption>Phase 4 GPU SVG</figcaption>
        </figure>
      </div>

      <h3>All SVG Snapshots</h3>
      <div id="svg-gallery" class="svg-gallery"></div>
    </section>

    <section>
      <h2>All Release Assets</h2>
      <ul id="asset-list" class="asset-list"></ul>
    </section>
  </main>
  <script src="./app.js"></script>
</body>
</html>
